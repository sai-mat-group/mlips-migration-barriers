{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91767,
     "status": "ok",
     "timestamp": 1747027618520,
     "user": {
      "displayName": "SaiMat01",
      "userId": "02241448083207383334"
     },
     "user_tz": -330
    },
    "id": "0jRU8FQK_kDL",
    "outputId": "fe5a4281-60f3-4173-b346-ddd9b7248c9f"
   },
   "outputs": [],
   "source": [
    "!pip install sevenn\n",
    "!pip install git+https://github.com/MDIL-SNU/SevenNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14642,
     "status": "ok",
     "timestamp": 1747030118975,
     "user": {
      "displayName": "SaiMat01",
      "userId": "02241448083207383334"
     },
     "user_tz": -330
    },
    "id": "7ovriIDdBnXr",
    "outputId": "9083276b-e181-40d2-a40a-6517e0a62d8e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the environment variable to reduce fragmentation before any GPU memory is allocated\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Import the calculator and trigger the checkpoint download.\n",
    "from sevenn.calculator import SevenNetCalculator\n",
    "\n",
    "# Instantiate a dummy calculator to ensure the checkpoint is downloaded.\n",
    "dummy_calc = SevenNetCalculator('7net-mf-ompa', modal='omat24')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Checkpoint downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFXrR_jk282p",
    "outputId": "d5919e3a-881e-4f17-a51d-172b6e1f1df6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.io import read, write\n",
    "from ase.mep import NEB\n",
    "from ase.optimize import BFGS, QuasiNewton\n",
    "from sevenn.calculator import SevenNetCalculator\n",
    "\n",
    "base_input_dir = '/content/drive/MyDrive/ALL'\n",
    "calc = dummy_calc\n",
    "\n",
    "skip_systems = {\n",
    "    \"Name of the folder, if any systems to skip\",\n",
    "}\n",
    "\n",
    "for root, dirs, files in os.walk(base_input_dir):\n",
    "    if 'initial' in dirs and 'final' in dirs:\n",
    "        initial_path = os.path.join(root, \"initial\", \"POSCAR\")\n",
    "        final_path = os.path.join(root, \"final\", \"POSCAR\")\n",
    "\n",
    "        if not (os.path.exists(initial_path) and os.path.exists(final_path)):\n",
    "            print(f\"Skipping {root}: POSCAR files not found.\")\n",
    "            continue\n",
    "\n",
    "        system_folder = root\n",
    "        system_name = os.path.basename(system_folder)\n",
    "        save_dir = os.path.join(system_folder, \"SevenNet_run_ACTUAL\")\n",
    "        csv_path = os.path.join(save_dir, \"energies.csv\")\n",
    "\n",
    "        if system_name in skip_systems or os.path.exists(csv_path):\n",
    "            reason = \"manual skip list\" if system_name in skip_systems else \"energies.csv exists\"\n",
    "            print(f\"Skipping system {system_name} as {reason}.\")\n",
    "            skip_systems.add(system_name)\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing system: {system_name}\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            initial = read(initial_path)\n",
    "            final = read(final_path)\n",
    "\n",
    "            mask_initial = [atom.tag > 1 for atom in initial]\n",
    "            initial.set_constraint(FixAtoms(mask=mask_initial))\n",
    "            mask_final = [atom.tag > 1 for atom in final]\n",
    "            final.set_constraint(FixAtoms(mask=mask_final))\n",
    "\n",
    "            initial.calc = calc\n",
    "            final.calc = calc\n",
    "\n",
    "            init_traj = os.path.join(save_dir, \"initial_relaxed.traj\")\n",
    "            final_traj = os.path.join(save_dir, \"final_relaxed.traj\")\n",
    "\n",
    "            print(f\"  ➤ Relaxing initial...\")\n",
    "            qn_init = QuasiNewton(initial, trajectory=init_traj)\n",
    "            qn_init.run(fmax=0.05, steps=1000)\n",
    "            write(os.path.join(save_dir, \"relaxed_initial.vasp\"), initial, format=\"vasp\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  ➤ Relaxing final...\")\n",
    "            qn_final = QuasiNewton(final, trajectory=final_traj)\n",
    "            qn_final.run(fmax=0.05, steps=1000)\n",
    "            write(os.path.join(save_dir, \"relaxed_final.vasp\"), final, format=\"vasp\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            initial = read(init_traj)\n",
    "            final = read(final_traj)\n",
    "            constraint = FixAtoms(mask=[atom.tag > 1 for atom in final])\n",
    "\n",
    "            images = [initial]\n",
    "            for i in range(3):\n",
    "                image = initial.copy()\n",
    "                image.set_constraint(constraint)\n",
    "                image.calc = calc\n",
    "                images.append(image)\n",
    "            images.append(final)\n",
    "\n",
    "            print(f\"  ➤ Running NEB...\")\n",
    "            neb = NEB(images, parallel=False, k=5, method='eb', allow_shared_calculator=True)\n",
    "            neb.interpolate('idpp')\n",
    "            neb_traj = os.path.join(save_dir, \"neb.traj\")\n",
    "\n",
    "            qn_neb = BFGS(neb, trajectory=neb_traj)\n",
    "            qn_neb.run(fmax=0.05, steps=1000)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            energies = []\n",
    "            with open(csv_path, mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"Image Index\", \"Energy (eV)\"])\n",
    "                for i, image in enumerate(images):\n",
    "                    try:\n",
    "                        energy = image.get_potential_energy()\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error computing energy for image {i} of {system_name}: {e}\")\n",
    "                        energy = None\n",
    "                    energies.append(energy)\n",
    "                    output_file = os.path.join(save_dir, f\"neb_optimized_{i}.vasp\")\n",
    "                    write(output_file, image, format=\"vasp\")\n",
    "                    writer.writerow([i, energy])\n",
    "\n",
    "            if None in energies:\n",
    "                print(f\"Skipping migration barrier for {system_name} due to energy errors.\")\n",
    "                continue\n",
    "\n",
    "            migration_barrier = max(energies) - min(energies)\n",
    "            print(f\"{system_name} - Migration Barrier: {migration_barrier:.6f} eV\")\n",
    "            with open(csv_path, mode=\"a\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([])\n",
    "                writer.writerow([\"Migration Barrier\", migration_barrier])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {system_name}: {e}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            continue\n",
    "\n",
    "print(\"\\n All NEB calculations complete!\")\n",
    "\n",
    "# Print skipped systems\n",
    "print(\"\\nSkipped systems:\")\n",
    "for name in sorted(skip_systems):\n",
    "    print(f\" - {name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2EEXHLn_uB0",
    "outputId": "4fd63769-63cf-40f9-c3af-399fa25011cf"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.io import read, write\n",
    "from ase.mep import NEB\n",
    "from ase.optimize import BFGS, QuasiNewton\n",
    "from sevenn.calculator import SevenNetCalculator\n",
    "import torch\n",
    "\n",
    "# Disable debugging validation to address frozen modules warning\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "\n",
    "# Check available GPUs and set device\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Base input directory\n",
    "base_input_dir = '/content/drive/MyDrive/MLIP_NEB_inputs'\n",
    "\n",
    "# Shared calculator for endpoints\n",
    "shared_calc = dummy_calc\n",
    "\n",
    "# Walk through the directory tree\n",
    "for root, dirs, files in os.walk(base_input_dir):\n",
    "    if 'initial' in dirs and 'final' in dirs:\n",
    "        initial_path = os.path.join(root, \"initial\", \"POSCAR\")\n",
    "        final_path = os.path.join(root, \"final\", \"POSCAR\")\n",
    "\n",
    "        if not (os.path.exists(initial_path) and os.path.exists(final_path)):\n",
    "            print(f\"Skipping {root}: initial or final POSCAR not found.\")\n",
    "            continue\n",
    "\n",
    "        system_name = os.path.basename(root)\n",
    "        print(f\"Processing system: {system_name}\")\n",
    "\n",
    "        save_dir = os.path.join(root, \"SevenNet_run\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        csv_path = os.path.join(save_dir, \"energies.csv\")\n",
    "\n",
    "        # Read and constrain structures\n",
    "        initial = read(initial_path)\n",
    "        final = read(final_path)\n",
    "        mask_initial = [atom.tag > 1 for atom in initial]\n",
    "        initial.set_constraint(FixAtoms(mask=mask_initial))\n",
    "        mask_final = [atom.tag > 1 for atom in final]\n",
    "        final.set_constraint(FixAtoms(mask=mask_final))\n",
    "\n",
    "        # Assign shared calculator\n",
    "        initial.calc = shared_calc\n",
    "        final.calc = shared_calc\n",
    "\n",
    "        # Relax initial structure\n",
    "        init_traj = os.path.join(save_dir, \"initial_relaxed.traj\")\n",
    "        qn = QuasiNewton(initial, trajectory=init_traj)\n",
    "        qn.run(fmax=0.05, steps=500)\n",
    "        write(os.path.join(save_dir, \"relaxed_initial.vasp\"), initial, format=\"vasp\")\n",
    "\n",
    "        # Relax final structure\n",
    "        final_traj = os.path.join(save_dir, \"final_relaxed.traj\")\n",
    "        qn = QuasiNewton(final, trajectory=final_traj)\n",
    "        qn.run(fmax=0.05, steps=1000)\n",
    "        write(os.path.join(save_dir, \"relaxed_final.vasp\"), final, format=\"vasp\")\n",
    "\n",
    "        # Reload relaxed structures\n",
    "        initial = read(init_traj)\n",
    "        final = read(final_traj)\n",
    "        mask_final = [atom.tag > 1 for atom in final]\n",
    "        constraint = FixAtoms(mask=mask_final)\n",
    "\n",
    "        # Create NEB images with fewer intermediates to reduce memory usage\n",
    "        images = [initial]\n",
    "        num_intermediates = 3  # Reduced from 7 to 3\n",
    "        for i in range(num_intermediates):\n",
    "            image = initial.copy()\n",
    "            # Use a new calculator per image, but we'll mitigate memory later\n",
    "            image.calc = SevenNetCalculator('7net-mf-ompa', modal='omat24', device=device)\n",
    "            image.set_constraint(constraint)\n",
    "            images.append(image)\n",
    "        images.append(final)\n",
    "\n",
    "        # Clear GPU memory before NEB\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"GPU memory allocated before NEB: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "        print(f\"GPU memory reserved before NEB: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "\n",
    "        # Run NEB with parallel=False to avoid GPU memory overload\n",
    "        try:\n",
    "            neb = NEB(images, parallel=False, k=5, method='eb')  # Changed to parallel=False\n",
    "            neb.interpolate('idpp')\n",
    "            neb_traj = os.path.join(save_dir, \"neb.traj\")\n",
    "            qn = BFGS(neb, trajectory=neb_traj)\n",
    "            qn.run(fmax=0.05, steps=1000)\n",
    "        except Exception as e:\n",
    "            print(f\"NEB failed for {system_name}: {e}. Skipping.\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        # Compute and save energies\n",
    "        energies = []\n",
    "        with open(csv_path, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Image Index\", \"Energy (eV)\"])\n",
    "            for i, image in enumerate(images):\n",
    "                try:\n",
    "                    energy = image.get_potential_energy()\n",
    "                except Exception as e:\n",
    "                    print(f\"Energy error for image {i} of {system_name}: {e}\")\n",
    "                    energy = None\n",
    "                energies.append(energy)\n",
    "                output_file = os.path.join(save_dir, f\"neb_optimized_{i}.vasp\")\n",
    "                write(output_file, image, format=\"vasp\")\n",
    "                writer.writerow([i, energy])\n",
    "\n",
    "        if None in energies:\n",
    "            print(f\"Skipping barrier calculation for {system_name} due to energy errors\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        migration_barrier = max(energies) - min(energies)\n",
    "        print(f\"{system_name} - Migration Barrier: {migration_barrier:.6f} eV\")\n",
    "        with open(csv_path, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([])\n",
    "            writer.writerow([\"Migration Barrier\", migration_barrier])\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"✅ All NEB Calculations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ks1q-hy0PnnT",
    "outputId": "d187cfc3-01b2-4394-f551-1e45c7836c3e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Import the calculator and trigger the checkpoint download.\n",
    "from sevenn.calculator import SevenNetCalculator\n",
    "\n",
    "# Instantiate a dummy calculator. This will check for and download the checkpoint if it isn't already present.\n",
    "dummy_calc = SevenNetCalculator('7net-mf-ompa', modal='omat24')\n",
    "del dummy_calc\n",
    "\n",
    "print(\"Checkpoint downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUBP3YqNPmUz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.io import read, write\n",
    "from ase.mep import NEB\n",
    "from ase.optimize import BFGS, QuasiNewton\n",
    "from sevenn.calculator import SevenNetCalculator\n",
    "\n",
    "# Set device to GPU (A100) if needed, e.g., device = 'cuda'\n",
    "base_input_dir = '/content/drive/MyDrive/MLIP_NEB_inputs'\n",
    "\n",
    "# Instantiate a shared calculator instance. The checkpoint is already available from Cell 1.\n",
    "calc = SevenNetCalculator('7net-mf-ompa', modal='omat24')\n",
    "\n",
    "# Walk through the directory tree under MLIP_NEB_inputs\n",
    "for root, dirs, files in os.walk(base_input_dir):\n",
    "    # Check if both \"initial\" and \"final\" folders are present in the current directory\n",
    "    if 'initial' in dirs and 'final' in dirs:\n",
    "        initial_path = os.path.join(root, \"initial\", \"POSCAR\")\n",
    "        final_path = os.path.join(root, \"final\", \"POSCAR\")\n",
    "\n",
    "        # Only process if both POSCAR files exist\n",
    "        if not (os.path.exists(initial_path) and os.path.exists(final_path)):\n",
    "            print(f\"Skipping {root}: initial or final POSCAR not found.\")\n",
    "            continue\n",
    "\n",
    "        system_folder = root  # This is the system's folder\n",
    "        system_name = os.path.basename(system_folder)\n",
    "        print(f\"Processing system: {system_name}\")\n",
    "\n",
    "        # Create a subfolder in the system folder for the NEB outputs\n",
    "        save_dir = os.path.join(system_folder, \"SevenNet_run\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # CSV file to record energies\n",
    "        csv_path = os.path.join(save_dir, \"energies.csv\")\n",
    "\n",
    "        # Read initial and final structures\n",
    "        initial = read(initial_path)\n",
    "        final = read(final_path)\n",
    "\n",
    "        # Apply constraints: fix atoms with tag > 1\n",
    "        mask_initial = [atom.tag > 1 for atom in initial]\n",
    "        initial.set_constraint(FixAtoms(mask=mask_initial))\n",
    "        mask_final = [atom.tag > 1 for atom in final]\n",
    "        final.set_constraint(FixAtoms(mask=mask_final))\n",
    "        # We'll use the final mask for the NEB images\n",
    "\n",
    "        # Assign the shared calculator to both endpoints\n",
    "        initial.calc = calc\n",
    "        final.calc = calc\n",
    "\n",
    "        # Relax the initial structure (steps reduced for testing)\n",
    "        init_traj = os.path.join(save_dir, \"initial_relaxed.traj\")\n",
    "        qn = QuasiNewton(initial, trajectory=init_traj)\n",
    "        qn.run(fmax=0.05, steps=500)\n",
    "        write(os.path.join(save_dir, \"relaxed_initial.vasp\"), initial, format=\"vasp\")\n",
    "\n",
    "        # Relax the final structure (steps reduced for testing)\n",
    "        final_traj = os.path.join(save_dir, \"final_relaxed.traj\")\n",
    "        qn = QuasiNewton(final, trajectory=final_traj)\n",
    "        qn.run(fmax=0.05, steps=1000)\n",
    "        write(os.path.join(save_dir, \"relaxed_final.vasp\"), final, format=\"vasp\")\n",
    "\n",
    "        # Reload relaxed structures\n",
    "        initial = read(init_traj)\n",
    "        final = read(final_traj)\n",
    "        mask_final = [atom.tag > 1 for atom in final]  # Recalculate based on relaxed final\n",
    "        constraint = FixAtoms(mask=mask_final)\n",
    "\n",
    "        images = [initial]\n",
    "        for i in range(7):\n",
    "            image = initial.copy()\n",
    "            # Assign a fresh SevenNet calculator to each image\n",
    "            image.calc = SevenNetCalculator('7net-mf-ompa', modal='omat24')\n",
    "            image.set_constraint(constraint)\n",
    "            images.append(image)\n",
    "        images.append(final)\n",
    "\n",
    "        # Set up and run the NEB calculation with error handling for memory issues\n",
    "        try:\n",
    "            neb = NEB(images, parallel=True, k=5, method='eb')\n",
    "            neb.interpolate('idpp')\n",
    "            neb_traj = os.path.join(save_dir, \"neb.traj\")\n",
    "            qn = BFGS(neb, trajectory=neb_traj)\n",
    "            qn.run(fmax=0.05, steps=1000)\n",
    "        except Exception as e:\n",
    "            print(f\"NEB calculation failed for system {system_name}: {e}. Skipping to the next system.\")\n",
    "            continue\n",
    "\n",
    "        # Compute and save energies for each image\n",
    "        energies = []\n",
    "        with open(csv_path, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Image Index\", \"Energy (eV)\"])\n",
    "            for i, image in enumerate(images):\n",
    "                try:\n",
    "                    energy = image.get_potential_energy()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error computing energy for image {i} of {system_name}: {e}\")\n",
    "                    energy = None\n",
    "                energies.append(energy)\n",
    "                output_file = os.path.join(save_dir, f\"neb_optimized_{i}.vasp\")\n",
    "                write(output_file, image, format=\"vasp\")\n",
    "                writer.writerow([i, energy])\n",
    "\n",
    "        # Check for any energy errors before calculating migration barrier\n",
    "        if None in energies:\n",
    "            print(f\"Skipping migration barrier calculation for {system_name} due to energy errors\")\n",
    "            continue\n",
    "\n",
    "        migration_barrier = max(energies) - min(energies)\n",
    "        print(f\"{system_name} - Migration Barrier: {migration_barrier:.6f} eV\")\n",
    "        with open(csv_path, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([])\n",
    "            writer.writerow([\"Migration Barrier\", migration_barrier])\n",
    "\n",
    "print(\"✅ All NEB Calculations complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "in5kyfrdAHI0"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive in Colab with forced remount to avoid duplicate mount warnings\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.io import read, write\n",
    "from ase.mep import NEB\n",
    "from ase.optimize import BFGS, QuasiNewton\n",
    "from sevenn.calculator import SevenNetCalculator\n",
    "\n",
    "# Set device to GPU (A100)\n",
    "#device = 'cuda'  # or 'cuda:0' if preferred\n",
    "base_input_dir = '/content/drive/MyDrive/MLIP_NEB_inputs'\n",
    "\n",
    "# Instantiate a single calculator instance to be shared by all images\n",
    "calc = SevenNetCalculator('7net-mf-ompa', modal='omat24')\n",
    "\n",
    "# Walk through the directory tree under MLIP_NEB_inputs\n",
    "for root, dirs, files in os.walk(base_input_dir):\n",
    "    # Check if both \"initial\" and \"final\" folders are present in the current directory\n",
    "    if 'initial' in dirs and 'final' in dirs:\n",
    "        initial_path = os.path.join(root, \"initial\", \"POSCAR\")\n",
    "        final_path = os.path.join(root, \"final\", \"POSCAR\")\n",
    "\n",
    "        # Only process if both POSCAR files exist\n",
    "        if not (os.path.exists(initial_path) and os.path.exists(final_path)):\n",
    "            print(f\"Skipping {root}: initial or final POSCAR not found.\")\n",
    "            continue\n",
    "\n",
    "        system_folder = root  # This is the system's folder\n",
    "        system_name = os.path.basename(system_folder)\n",
    "        print(f\"Processing system: {system_name}\")\n",
    "\n",
    "        # Create a subfolder in the system folder for the NEB outputs\n",
    "        save_dir = os.path.join(system_folder, \"SevenNet_run\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # CSV file to record energies\n",
    "        csv_path = os.path.join(save_dir, \"energies.csv\")\n",
    "        if os.path.exists(csv_path):\n",
    "          print(f\"Skipping {structure_name}: energies.csv already exists.\")\n",
    "          continue\n",
    "\n",
    "        # Read initial and final structures\n",
    "        initial = read(initial_path)\n",
    "        final = read(final_path)\n",
    "\n",
    "        # Apply constraints: fix atoms with tag > 1\n",
    "        mask_initial = [atom.tag > 1 for atom in initial]\n",
    "        initial.set_constraint(FixAtoms(mask=mask_initial))\n",
    "        mask_final = [atom.tag > 1 for atom in final]\n",
    "        final.set_constraint(FixAtoms(mask=mask_final))\n",
    "        # We'll use the final mask for the NEB images\n",
    "\n",
    "        # Assign the shared calculator to both endpoints\n",
    "\n",
    "        initial.calc = calc\n",
    "        final.calc = calc\n",
    "\n",
    "        # Relax the initial structure (steps reduced for testing)\n",
    "        init_traj = os.path.join(save_dir, \"initial_relaxed.traj\")\n",
    "        qn = QuasiNewton(initial, trajectory=init_traj)\n",
    "        qn.run(fmax=0.05, steps=500)\n",
    "        write(os.path.join(save_dir, \"relaxed_initial.vasp\"), initial, format=\"vasp\")\n",
    "\n",
    "        # Relax the final structure (steps reduced for testing)\n",
    "        final_traj = os.path.join(save_dir, \"final_relaxed.traj\")\n",
    "        qn = QuasiNewton(final, trajectory=final_traj)\n",
    "        qn.run(fmax=0.05, steps=1000)\n",
    "        write(os.path.join(save_dir, \"relaxed_final.vasp\"), final, format=\"vasp\")\n",
    "\n",
    "        # Reload relaxed structures\n",
    "        initial = read(init_traj)\n",
    "        final = read(final_traj)\n",
    "\n",
    "        # Create NEB images (7 intermediate images)\n",
    "        constraint = FixAtoms(mask=mask_final)\n",
    "        images = [initial]\n",
    "        for i in range(7):\n",
    "            image = initial.copy()\n",
    "            # Assign a fresh CHGNet calculator to each image\n",
    "            image.calc = SevenNetCalculator('7net-mf-ompa', modal='omat24')\n",
    "            image.set_constraint(constraint)\n",
    "            images.append(image)\n",
    "        images.append(final)\n",
    "\n",
    "        # Set up and run the NEB calculation with parallel evaluation turned off to reduce resource usage\n",
    "        neb = NEB(images, parallel=True, k=5, method='eb')\n",
    "        neb.interpolate('idpp')\n",
    "        neb_traj = os.path.join(save_dir, \"neb.traj\")\n",
    "        qn = BFGS(neb, trajectory=neb_traj)\n",
    "        qn.run(fmax=0.05, steps=1000)\n",
    "\n",
    "        # Compute and save energies for each image\n",
    "        energies = []\n",
    "        with open(csv_path, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Image Index\", \"Energy (eV)\"])\n",
    "            for i, image in enumerate(images):\n",
    "                try:\n",
    "                    energy = image.get_potential_energy()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error computing energy for image {i} of {system_name}: {e}\")\n",
    "                    energy = None\n",
    "                energies.append(energy)\n",
    "                output_file = os.path.join(save_dir, f\"neb_optimized_{i}.vasp\")\n",
    "                write(output_file, image, format=\"vasp\")\n",
    "                writer.writerow([i, energy])\n",
    "\n",
    "        # Check for any energy errors before calculating migration barrier\n",
    "        if None in energies:\n",
    "            print(f\"Skipping migration barrier calculation for {system_name} due to energy errors\")\n",
    "            continue\n",
    "\n",
    "        migration_barrier = max(energies) - min(energies)\n",
    "        print(f\"{system_name} - Migration Barrier: {migration_barrier:.6f} eV\")\n",
    "        with open(csv_path, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([])\n",
    "            writer.writerow([\"Migration Barrier\", migration_barrier])\n",
    "\n",
    "print(\"✅ All NEB Calculations complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347891,
     "status": "ok",
     "timestamp": 1747652447648,
     "user": {
      "displayName": "SaiMat01",
      "userId": "02241448083207383334"
     },
     "user_tz": -330
    },
    "id": "y8nIP6OYCHxx",
    "outputId": "b8f7342c-366a-448a-a6e3-c2b73acd2bc4"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect migration-barrier values from every SevenNet_run_ACTUAL folder and\n",
    "write them to a CSV whose location you choose.\n",
    "\n",
    "✓ Works in Google Colab (after drive.mount) or on your local machine.\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import pathlib\n",
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# then run the script cell above, changing DEST_CSV if you like\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1) --- CONFIGURATION -------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "ROOT = pathlib.Path(\"/content/drive/MyDrive/ALL\")   # top directory to scan\n",
    "TARGET_DIRNAME = \"ORBV2_run\"              # folder to locate\n",
    "ENERGY_FILE = \"energies.csv\"                        # file inside that folder\n",
    "\n",
    "# --- Choose the destination for the summary CSV ----------------------------\n",
    "# Option A – hard-code it here:\n",
    "DEST_CSV = pathlib.Path(\"/content/drive/MyDrive/Results/OrbV2.csv\")\n",
    "\n",
    "# Option B – or supply it on the command line:\n",
    "if len(sys.argv) == 2:\n",
    "    DEST_CSV = pathlib.Path(sys.argv[1])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2) --- MAIN ----------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for snet_dir in ROOT.rglob(TARGET_DIRNAME):\n",
    "    if not snet_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    parent_name = snet_dir.parent.name\n",
    "    energies_path = snet_dir / ENERGY_FILE\n",
    "\n",
    "    if not energies_path.exists():\n",
    "        print(f\"⚠️  Skip {snet_dir}: {ENERGY_FILE} not found\")\n",
    "        continue\n",
    "\n",
    "    # read last non-blank line\n",
    "    last_line = next((line.strip() for line in reversed(energies_path.read_text().splitlines()) if line.strip()), None)\n",
    "    if last_line is None:\n",
    "        print(f\"⚠️  Skip {snet_dir}: {ENERGY_FILE} empty\")\n",
    "        continue\n",
    "\n",
    "    # split on comma or whitespace; take final token\n",
    "    token = last_line.replace(\",\", \" \").split()[-1]\n",
    "    try:\n",
    "        barrier = float(token)\n",
    "    except ValueError:\n",
    "        print(f\"⚠️  Skip {snet_dir}: cannot parse number in → {last_line!r}\")\n",
    "        continue\n",
    "\n",
    "    results.append((parent_name, barrier))\n",
    "    print(f\"✔︎  {parent_name:25s}  {barrier}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3) --- WRITE THE OUTPUT CSV ------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "if not results:\n",
    "    print(\"\\nNo valid records found – nothing to write.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# make sure the parent folder exists\n",
    "DEST_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with DEST_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"parent_directory\", \"migration_barrier\"])\n",
    "    writer.writerows(sorted(results))\n",
    "\n",
    "print(f\"\\nSaved {len(results)} entries to: {DEST_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCfUp2aTLr0J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMkZs9hOydr8SiPgba49eNt",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
